{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb373fbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6208c385",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark.sql.functions as f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8fcf88f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "642c726c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import StructField,IntegerType, FloatType, BooleanType ,StructType,StringType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "971b8bba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.dataframe import DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cd7f40c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7495c1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import Row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61e6ea49",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccb36306",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33cd47d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7356e3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7ecf75c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e170e8e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db38c042",
   "metadata": {},
   "outputs": [],
   "source": [
    "camposX=[    StructField('ano',StringType(),True),  \n",
    "             StructField('id_cliente',IntegerType(),True),\n",
    "             StructField('id_plano',IntegerType(),True),\n",
    "             StructField('plano_id',IntegerType(),True),\n",
    "             StructField('vjan',FloatType(),True),\n",
    "             StructField('vfev',FloatType(),True),\n",
    "             StructField('vmar',FloatType(),True),\n",
    "             StructField('vabr',FloatType(),True)\n",
    "       ]\n",
    "camposXStruct=StructType(fields=camposX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8ab8252",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = (\n",
    "    SparkSession\n",
    "    .builder\n",
    "    .master(\"local\")\n",
    "    .appName(\"test-Cosmer\")\n",
    "    .config(\"spark.sql.shuffle.partitions\", 13)\n",
    "    .config(\"spark.driver.memory\", \"10g\")\n",
    "    .config(\"spark.sql.legacy.createHiveTableByDefault\", \"false\")\n",
    "    .config(\"setLogLevel\", \"INFO\")\n",
    "    .config(\"spark.logConf\", \"true\")\n",
    "    .getOrCreate()\n",
    ")\n",
    "#spark.sparkContext.setLogLevel(\"WARN\")  \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99d4b37a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# leitura do csv de contratos\n",
    "df_pagax = spark.read.csv('pagaX.csv', header=True, sep=';',schema=camposPagaXStruct)\n",
    "# leitura do csv de contratos\n",
    "df_pagay = spark.read.csv('pagaY.csv', header=True, sep=';',schema=camposPagaYStruct)\n",
    "#type(df_planos)\n",
    "df_pagax.show()\n",
    "df_igual = df_pagay.show()\n",
    "listaPagtosN = []\n",
    "\n",
    "#df_pagai = df_pagax.rdd.map(lambda x: (x.name, x.age, x.city))\n",
    "for row in df_pagax.rdd.toLocalIterator():\n",
    "    print(row['ano'])\n",
    "#type(df_planos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75c510b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clientes.createOrReplaceTempView(\"Clientes\")\n",
    "#type(df_clientes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acd60a75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# definição do esquema da tabela temporária de transações\n",
    "spark.sql(\"SELECT * FROM Clientes\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "910246b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# leitura do csv de contratos\n",
    "df_planos = spark.read.csv('planos.csv', header=True, sep=';',schema=planosStruct)\n",
    "#type(df_planos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c9d6bae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8e79648",
   "metadata": {},
   "outputs": [],
   "source": [
    " .rdd.collect()\n",
    "    qtd_meses = 0\n",
    "    id = int(row['id'])\n",
    "    str_date = row['data_pagamento']\n",
    "    date = datetime.strptime(str_date, '%d/%m/%Y').date()\n",
    "    #ano = f.colyear(row['data_pagamento'])\n",
    "    #mes = f.month(row['data_pagamento'])\n",
    "    #print(date, type(date))\n",
    "    ano = str(date)[0:4]\n",
    "    mes = str(date)[5:7]\n",
    "    valor = float(row['valor'].replace('R$','').replace(',','.')) # float()\n",
    "    meses = int(row['qtde_meses_pagos'])\n",
    "    valorM = float(valor / meses)\n",
    "    while qtd_meses < meses:\n",
    "        if qtd_meses != 0:\n",
    "            if mes == '12':\n",
    "                mes = '01'\n",
    "                ano = str(int(ano)+1)\n",
    "            else:\n",
    "                mes = str(int(mes)+1)\n",
    "                if len(mes) == 1:\n",
    "                    mes = '0'+mes\n",
    "        anomes = ano + mes\n",
    "        #print(anomes)\n",
    "        #str_date = '2018-07-11'\n",
    "        #date = datetime.strptime(str_date, '%Y-%m-%d').date()\n",
    "        #print(date, type(date))\n",
    "        dataP = date\n",
    "        #print(row['id'], anomes , valorM , row['plano_id'], row['qtde_meses_pagos'], qtd_meses)\n",
    "        linha = []\n",
    "        linha.append(row['id'])\n",
    "        linha.append(anomes)\n",
    "        linha.append(valorM)\n",
    "        linha.append(int(row['plano_id']))\n",
    "        listaPagtos.append(linha)\n",
    "        qtd_meses = qtd_meses + 1\n",
    "        #print ('================')\n",
    "del(df_pagamentosHj)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
